{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "flower_classification_r1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "heVNRMRwsj-2",
        "colab_type": "text"
      },
      "source": [
        "# Mount the drive data\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThqafgqpFKxJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "61643532-dc6d-4f97-a87b-b6a3619a034a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drQpuLUpszqV",
        "colab_type": "text"
      },
      "source": [
        "# Import all required libraries\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IH0Dwdo2BMde",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "from os import walk\n",
        "import glob\n",
        "import shutil\n",
        "import re\n",
        "\n",
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import seaborn as sns\n",
        "import sklearn\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D\n",
        "from keras.models import load_model\n",
        "from keras.optimizers import RMSprop, Adam\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from keras.preprocessing import image\n",
        "from keras.applications import VGG16\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.models import Model\n",
        "from keras.applications.imagenet_utils import preprocess_input, decode_predictions\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wgc6F0PeG1yj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PARENT_PATH  = '/content/drive/My Drive/Flower_Classification'\n",
        "IMAGES_PATH  = '/content/drive/My Drive/Flower_Classification/Images'\n",
        "MAT_PATH     = '/content/drive/My Drive/Flower_Classification'\n",
        "MAT_NAME     = 'datasplits.mat'\n",
        "SAVED_MODELS = '/content/drive/My Drive/Flower_Classification/trained_model'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7x-79T7tOPN",
        "colab_type": "text"
      },
      "source": [
        "read the mat files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XuBJUfkK4Dyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class preprocess:\n",
        "\n",
        "  def __init__(self, mat_path = None, mat_file_name = None, image_path = None, parent_path = None):\n",
        "    self.parent_path = parent_path\n",
        "    self.image_path  = image_path\n",
        "    self.mat         = sio.loadmat(mat_path + '/' + mat_file_name)\n",
        "    \n",
        "    \n",
        "    # collect train, test, valid in seperate dict\n",
        "    self.train_idx   = {'train_' + str(i[0]) : self.mat[i[1]].ravel().tolist() for i in zip([1,2,3],['trn1', 'trn2', 'trn3'])}\n",
        "    self.test_idx    = {'test_'  + str(i[0]) : self.mat[i[1]].ravel().tolist() for i in zip([1,2,3],['tst1', 'tst2', 'tst3'])}\n",
        "    self.valid_idx   = {'valid_' + str(i[0]) : self.mat[i[1]].ravel().tolist() for i in zip([1,2,3],['val1', 'val2', 'val3'])}\n",
        "\n",
        "\n",
        "    # collect respective train/test/valid idx for 3 different models \n",
        "    self.data1       = [i for i in zip(self.train_idx ,  self.test_idx,  self.valid_idx)][0]\n",
        "    self.data2       = [i for i in zip(self.train_idx ,  self.test_idx,  self.valid_idx)][1]\n",
        "    self.data3       = [i for i in zip(self.train_idx ,  self.test_idx,  self.valid_idx)][2]\n",
        "\n",
        "    self.data1_idx   = {self.data1[0] : self.train_idx[self.data1[0]], self.data1[1] : self.test_idx[self.data1[1]], self.data1[2] : self.valid_idx[self.data1[2]]}\n",
        "    self.data2_idx   = {self.data2[0] : self.train_idx[self.data2[0]], self.data2[1] : self.test_idx[self.data2[1]], self.data2[2] : self.valid_idx[self.data2[2]]}\n",
        "    self.data3_idx   = {self.data3[0] : self.train_idx[self.data3[0]], self.data3[1] : self.test_idx[self.data3[1]], self.data3[2] : self.valid_idx[self.data3[2]]}\n",
        "\n",
        "    # save the indices as image file names \n",
        "    self.data1_img   = {}\n",
        "    self.data2_img   = {}\n",
        "    self.data3_img   = {}\n",
        "\n",
        "  def indices_to_img_names(self):\n",
        "    dic = [self.data1_img, self.data2_img, self.data3_img]\n",
        "    for i, data in enumerate([self.data1_idx, self.data2_idx, self.data3_idx]):\n",
        "      for key, value in data.items(): \n",
        "        temp_list = []\n",
        "        for idx in value:\n",
        "          temp_list.append('image_' + str(idx).zfill(4) + '.jpg')\n",
        "        dic[i][key] = temp_list\n",
        "    return dic[0], dic[1], dic[2] \n",
        "\n",
        "  def create_folders_ImageName_with_labels(self, datasplits):\n",
        "    for dir_name in datasplits.keys():\n",
        "      print('Create a new folder - ' + dir_name)\n",
        "      new_folder = os.path.join(self.parent_path, dir_name) \n",
        "      os.mkdir(new_folder) # create a new folder\n",
        "\n",
        "      for (dirpath, dirnames, filenames) in walk(self.image_path):\n",
        "        if len(filenames)!=0:\n",
        "          common_image_names = np.intersect1d(datasplits[dir_name], filenames)\n",
        "          label = dirpath.split('/')[-1]\n",
        "          \n",
        "          print('Copying selected Images to the created directory ' + dir_name)\n",
        "          for img in common_image_names:\n",
        "            shutil.copy(os.path.join(dirpath, img), os.path.join(new_folder, img.split('.')[0] + '_' + label + '.jpg'))\n",
        "    return\n",
        "\n",
        "  def create_folders_model_training(self, datasplits):\n",
        "    for dir_name in datasplits.keys():\n",
        "      print('Create a new folder - ' + dir_name)\n",
        "      new_folder = os.path.join(self.parent_path, dir_name) \n",
        "      os.mkdir(new_folder) # create a new folder\n",
        "\n",
        "      for (dirpath, dirnames, filenames) in walk(self.image_path):\n",
        "        if len(filenames)!=0:\n",
        "          common_image_names = np.intersect1d(datasplits[dir_name], filenames)\n",
        "          folder_label = dirpath.split('/')[-1]\n",
        "          \n",
        "          print('Copying selected Images to the created directory ' + dir_name)\n",
        "          flower_folder = os.path.join(self.parent_path + '/' + dir_name, folder_label)\n",
        "          os.mkdir(flower_folder)\n",
        "          for img in common_image_names:\n",
        "            shutil.copy(os.path.join(dirpath, img), os.path.join(flower_folder, img))\n",
        "    return\n",
        "\n",
        "  def unpack_indices(self):\n",
        "    return self.data1_img, self.data2_img, self.data3_img\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\": \n",
        "  cls             = preprocess(MAT_PATH, MAT_NAME, IMAGES_PATH, PARENT_PATH)\n",
        "  d1, d2, d3      = cls.indices_to_img_names()\n",
        "  folder_creation = cls.create_folders_model_training(d1) # based on the split select d1, d2 or d3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-DKL-akAI00p",
        "colab_type": "text"
      },
      "source": [
        "# Model & calling Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rLg-mXGFt9g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pretrained_VGG16(train_set = None, valid_set = None, test_set = None):\n",
        "\n",
        "  # VGG16 was designed to work on 224 x 224 pixel input images sizes\n",
        "  img_rows = 224\n",
        "  img_cols = 224 \n",
        "\n",
        "  # Re-loads the VGG16 model without the top or FC layers\n",
        "  vgg16 = VGG16(weights = 'imagenet', include_top = False,  input_shape = (img_rows, img_cols, 3))\n",
        "\n",
        "  # Here we freeze the last 4 layers, layers are set to trainable as True by default\n",
        "  for layer in vgg16.layers[:10]: #vgg16.layers[:5]\n",
        "      layer.trainable = False\n",
        "\n",
        "  train_data_dir      = PARENT_PATH + '/' + train_set\n",
        "  validation_data_dir = PARENT_PATH + '/' + valid_set\n",
        "  test_data_dir       = PARENT_PATH + '/' + test_set\n",
        "\n",
        "  train_datagen       = ImageDataGenerator(rescale=1./255, rotation_range=20, width_shift_range=0.2, height_shift_range=0.2, horizontal_flip=True, fill_mode='nearest')\n",
        "  validation_datagen  = ImageDataGenerator(rescale=1./255)\n",
        "  test_datagen        = ImageDataGenerator(rescale=1./255)\n",
        "  \n",
        "  train_batchsize     = 64\n",
        "  val_batchsize       = 64\n",
        "  \n",
        "  train_generator     = train_datagen.flow_from_directory(train_data_dir, target_size=(img_rows, img_cols),  batch_size=train_batchsize, class_mode='categorical')\n",
        "  validation_generator= validation_datagen.flow_from_directory(validation_data_dir, target_size=(img_rows, img_cols),  batch_size=val_batchsize, class_mode='categorical', shuffle=False)\n",
        "  test_generator      = test_datagen.flow_from_directory(test_data_dir, target_size=(img_rows, img_cols), batch_size=64, class_mode='categorical', shuffle=False)\n",
        "\n",
        "  return vgg16, train_generator, validation_generator, test_generator\n",
        "\n",
        "def addTopModel(bottom_model, num_classes, D=256):\n",
        "  \"\"\"creates the top or head of the model that will be placed ontop of the bottom layers\"\"\"\n",
        "  top_model = bottom_model.output\n",
        "  top_model = Flatten(name = \"flatten\")(top_model)\n",
        "  top_model = Dense(D, activation = \"relu\")(top_model)\n",
        "  top_model = Dropout(0.3)(top_model)\n",
        "  top_model = Dense(num_classes, activation = \"softmax\")(top_model)\n",
        "\n",
        "  return top_model\n",
        "\n",
        "def model_processing():\n",
        "  vgg16, train_generator, validation_generator, test_generator = pretrained_VGG16()\n",
        "\n",
        "  num_classes   = 17\n",
        "  FC_Head       = addTopModel(vgg16, num_classes)\n",
        "  model         = Model(inputs=vgg16.input, outputs=FC_Head)\n",
        "  model.summary()\n",
        "\n",
        "\n",
        "  checkpoint    = ModelCheckpoint(PARENT_PATH + '/trained_model/weights-improvement_train3 -{epoch:02d}-{val_accuracy:.2f}.hdf5', monitor= \"val_accuracy\", mode=\"max\", save_best_only = True,verbose=1)\n",
        "  earlystop     = EarlyStopping(monitor = 'val_loss',  min_delta = 0,  patience = 3, verbose = 1, restore_best_weights = True)\n",
        "  reduce_lr     = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.2, patience = 3, verbose = 1, min_delta = 0.0001)\n",
        "  callbacks     = [checkpoint, reduce_lr]\n",
        "\n",
        "  model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(), metrics = ['accuracy'])\n",
        "\n",
        "  nb_train_samples      = 1224\n",
        "  nb_validation_samples = 250\n",
        "  epochs                = 25\n",
        "  batch_size            = 64\n",
        "\n",
        "  history               = model.fit_generator(train_generator, steps_per_epoch = nb_train_samples // batch_size, epochs = epochs,\n",
        "                                              callbacks = callbacks, validation_data = validation_generator, validation_steps = nb_validation_samples // batch_size)\n",
        "\n",
        "\n",
        "  print(history.history.keys())\n",
        "\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.grid(True)\n",
        "  plt.legend(['train', 'validation'], loc='upper left')\n",
        "  plt.show()\n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.grid(True)\n",
        "  plt.legend(['train', 'validation'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  return\n",
        "\n",
        "# Evalute the model\n",
        "splits = [['train_1', 'valid_1', 'test_1'],['train_2', 'valid_2', 'test_2'],['train_3', 'valid_3', 'test_3']]\n",
        "def evaluate_model(TrainedModel = None, Splits = None):\n",
        "   _, train_generator, validation_generator, test_generator = pretrained_VGG16(train_set = Splits[0], valid_set = Splits[1], test_set = Splits[2])\n",
        "   #TrainedModel.evaluate(train_generator)\n",
        "   valid_loss, valid_acc  = TrainedModel.evaluate(validation_generator)\n",
        "   test_loss, test_acc = TrainedModel.evaluate(test_generator)\n",
        "   return valid_loss, valid_acc , test_loss, test_acc\n",
        "\n",
        "# valid_loss, valid_acc , test_loss, test_acc = evaluate_model(TrainedModelSplit_1, splits[0])\n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gAOG7LtNIv6i",
        "colab_type": "text"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ow1nP0XVJHyF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "splits = [['train_1', 'valid_1', 'test_1'],['train_2', 'valid_2', 'test_2'],['train_3', 'valid_3', 'test_3']]\n",
        "def prediction(split_no = 0, Model = None):\n",
        "  split  =  splits[split_no]\n",
        "  _, train_generator, validation_generator, test_generator = pretrained_VGG16(train_set = split[0], valid_set = split[1], test_set = split[2])\n",
        "  prediction = np.argmax(Model.predict(test_generator), axis=1)\n",
        "  actual = [test_generator.class_indices[i.split('/')[0]] for i in test_generator.filenames if i.split('/')[0] in list(test_generator.class_indices.keys())]\n",
        "  print(f'Accuracy of the model for split no {split_no}:', accuracy_score(actual, prediction))\n",
        "  return prediction, actual\n",
        "\n",
        "# Call all the 3 splits & respective Trained model\n",
        "prediction(0, TrainedModelSplit_1)\n",
        "prediction(1, TrainedModelSplit_2)\n",
        "prediction(2, TrainedModelSplit_3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHVmBqijxyxK",
        "colab_type": "text"
      },
      "source": [
        "# Loading the saved Image & predict with Pictures"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53AZKfly7Tml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load the best trained models from 3 diffferent splits\n",
        "\n",
        "TrainedModelSplit_1 = load_model(SAVED_MODELS + '/weights-improvement-15-0.86.hdf5')\n",
        "TrainedModelSplit_2 = load_model(SAVED_MODELS + '/weights-improvement_train2 -21-0.88.hdf5')\n",
        "TrainedModelSplit_3 = load_model(SAVED_MODELS + '/weights-improvement_train3 -13-0.87.hdf5')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJonw-go13MN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "26209347-64ef-47da-9b2c-4b638318203e"
      },
      "source": [
        "class_labels = validation_generator.class_indices\n",
        "class_labels = {v: k for k, v in class_labels.items()}\n",
        "classes = list(class_labels.values())\n",
        "print(class_labels)\n",
        "\n",
        "# checking model on validation data\n",
        "def getRandomImage(path, img_width, img_height):\n",
        "    \"\"\"function loads a random images from a random folder in our validation path \"\"\"\n",
        "    folders = list(filter(lambda x: os.path.isdir(os.path.join(path, x)), os.listdir(path)))\n",
        "    random_directory = np.random.randint(0,len(folders))\n",
        "    path_class = folders[random_directory]\n",
        "    file_path = path + path_class\n",
        "    file_names = [f for f in listdir(file_path) if isfile(join(file_path, f))]\n",
        "    random_file_index = np.random.randint(0,len(file_names))\n",
        "    image_name = file_names[random_file_index]\n",
        "    final_path = file_path + \"/\" + image_name\n",
        "    return image.load_img(final_path, target_size = (img_width, img_height)), final_path, path_class\n",
        "\n",
        "# dimensions of our images\n",
        "img_width, img_height = 224, 224\n",
        "\n",
        "files = []\n",
        "predictions = []\n",
        "true_labels = []\n",
        "\n",
        "# predicting images\n",
        "for i in range(0, 5):\n",
        "    path = PARENT_PATH + '/test_1/'\n",
        "    img, final_path, true_label = getRandomImage(path, img_width, img_height)\n",
        "    files.append(final_path)\n",
        "    true_labels.append(true_label)\n",
        "    x = image.img_to_array(img)\n",
        "    x = x * 1./255\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    images = np.vstack([x])\n",
        "    classes = np.argmax(trained_model.predict(images, batch_size = 10))\n",
        "    predictions.append(classes)\n",
        "    \n",
        "for i in range(0, len(files)):\n",
        "    img=mpimg.imread((files[i]))\n",
        "    print(\"\\n(\",i+1,\")\")\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    print(\"Predicted: \",class_labels[predictions[i]])\n",
        "    print(\"True: \",true_labels[i])\n",
        "\n",
        "\n",
        "def intersection(lst1, lst2): \n",
        "  \n",
        "    lst3 = [value for value in lst1 if value in lst2] \n",
        "    return lst3\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{0: 'Bluebell', 1: 'Buttercup', 2: \"Colts'Foot\", 3: 'Cowslip', 4: 'Crocus', 5: 'Daffodil', 6: 'Daisy', 7: 'Dandelion', 8: 'Fritillary', 9: 'Iris', 10: 'LilyValley', 11: 'Pansy', 12: 'Snowdrop', 13: 'Sunflower', 14: 'Tigerlily', 15: 'Tulip', 16: 'Windflower'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# predicting images\\nfor i in range(0, 5):\\n    path = PARENT_PATH + \\'/test_1/\\'\\n    img, final_path, true_label = getRandomImage(path, img_width, img_height)\\n    files.append(final_path)\\n    true_labels.append(true_label)\\n    x = image.img_to_array(img)\\n    x = x * 1./255\\n    x = np.expand_dims(x, axis=0)\\n    images = np.vstack([x])\\n    classes = np.argmax(trained_model.predict(images, batch_size = 10))\\n    predictions.append(classes)\\n    \\nfor i in range(0, len(files)):\\n    img=mpimg.imread((files[i]))\\n    print(\"\\n(\",i+1,\")\")\\n    plt.imshow(img)\\n    plt.axis(\\'off\\')\\n    plt.show()\\n    print(\"Predicted: \",class_labels[predictions[i]])\\n    print(\"True: \",true_labels[i])\\n\\n\\ndef intersection(lst1, lst2): \\n  \\n    lst3 = [value for value in lst1 if value in lst2] \\n    return lst3\\n\\n\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    }
  ]
}